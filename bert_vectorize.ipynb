{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WARNING** : this is not entirely our code, the original source can be found there : \n",
    "https://towardsdatascience.com/3-types-of-contextualized-word-embeddings-from-bert-using-transfer-learning-81fcefe3fe6d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3212,
     "status": "ok",
     "timestamp": 1669896853113,
     "user": {
      "displayName": "Mathis Randl",
      "userId": "00190129247534467029"
     },
     "user_tz": -60
    },
    "id": "JQI-ym_whmyU",
    "outputId": "781b9727-27c8-49b8-afeb-f4567e04c71a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# !pip install transformers\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import tqdm\n",
    "\n",
    "import pickle\n",
    "\n",
    "model = BertModel.from_pretrained('bert-base-uncased', output_hidden_states = True)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 309,
     "status": "ok",
     "timestamp": 1669896856758,
     "user": {
      "displayName": "Mathis Randl",
      "userId": "00190129247534467029"
     },
     "user_tz": -60
    },
    "id": "eHPGfkUownRc"
   },
   "outputs": [],
   "source": [
    "def readFileOfTweets(path):\n",
    "    ret = None\n",
    "    with open(path, \"r\") as f:\n",
    "        ret = f.read().splitlines()\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = readFileOfTweets('data/test_data.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 236,
     "status": "ok",
     "timestamp": 1669896725503,
     "user": {
      "displayName": "Mathis Randl",
      "userId": "00190129247534467029"
     },
     "user_tz": -60
    },
    "id": "LCV7QdiAx8W5"
   },
   "outputs": [],
   "source": [
    "negStrings = readFileOfTweets('data/train_neg_full.txt')\n",
    "negDf = pd.DataFrame(negStrings, columns=['text'])\n",
    "negDf['y'] = 0\n",
    "\n",
    "posStrings = readFileOfTweets('data/train_pos_full.txt')\n",
    "posDf = pd.DataFrame(posStrings, columns=['text'])\n",
    "posDf['y'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1669896725921,
     "user": {
      "displayName": "Mathis Randl",
      "userId": "00190129247534467029"
     },
     "user_tz": -60
    },
    "id": "ckzO8V9DiZ4n",
    "outputId": "784fd5a9-e67b-4411-eb8c-ff4cac30f350"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;user&gt; i dunno justin read my mention or not ....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>because your logic is so dumb , i won't even c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\" &lt;user&gt; just put casper in a box ! \" looved t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;user&gt; &lt;user&gt; thanks sir &gt; &gt; don't trip lil ma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>visiting my brother tmr is the bestest birthda...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1249995</th>\n",
       "      <td>a warning sign ? (; rt &lt;user&gt; the negativity y...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1249996</th>\n",
       "      <td>&lt;user&gt; ff too thank youuu ) )</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1249997</th>\n",
       "      <td>i just love shumpa ! that's my girl</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1249998</th>\n",
       "      <td>the best way to start a day ! no matter what h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1249999</th>\n",
       "      <td>#frenchieswant1dtou i'm not from french but &lt;u...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1250000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text  y\n",
       "0        <user> i dunno justin read my mention or not ....  1\n",
       "1        because your logic is so dumb , i won't even c...  1\n",
       "2        \" <user> just put casper in a box ! \" looved t...  1\n",
       "3        <user> <user> thanks sir > > don't trip lil ma...  1\n",
       "4        visiting my brother tmr is the bestest birthda...  1\n",
       "...                                                    ... ..\n",
       "1249995  a warning sign ? (; rt <user> the negativity y...  1\n",
       "1249996                      <user> ff too thank youuu ) )  1\n",
       "1249997                i just love shumpa ! that's my girl  1\n",
       "1249998  the best way to start a day ! no matter what h...  1\n",
       "1249999  #frenchieswant1dtou i'm not from french but <u...  1\n",
       "\n",
       "[1250000 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 231,
     "status": "ok",
     "timestamp": 1669896750355,
     "user": {
      "displayName": "Mathis Randl",
      "userId": "00190129247534467029"
     },
     "user_tz": -60
    },
    "id": "CHQusIZyifXm"
   },
   "outputs": [],
   "source": [
    "def bert_text_preparation(text, tokenizer):\n",
    "    \"\"\"Preparing the input for BERT\n",
    "    \n",
    "    Takes a string argument and performs\n",
    "    pre-processing like adding special tokens,\n",
    "    tokenization, tokens to ids, and tokens to\n",
    "    segment ids. All tokens are mapped to seg-\n",
    "    ment id = 1.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Text to be converted\n",
    "        tokenizer (obj): Tokenizer object\n",
    "            to convert text into BERT-re-\n",
    "            adable tokens and ids\n",
    "        \n",
    "    Returns:\n",
    "        list: List of BERT-readable tokens\n",
    "        obj: Torch tensor with token ids\n",
    "        obj: Torch tensor segment ids\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "    tokenized_text = tokenizer.tokenize(marked_text)\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    segments_ids = [1]*len(indexed_tokens)\n",
    "\n",
    "    # Convert inputs to PyTorch tensors\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    segments_tensors = torch.tensor([segments_ids])\n",
    "\n",
    "    return tokenized_text, tokens_tensor, segments_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 507,
     "status": "ok",
     "timestamp": 1669897262675,
     "user": {
      "displayName": "Mathis Randl",
      "userId": "00190129247534467029"
     },
     "user_tz": -60
    },
    "id": "PYB4cKvroKgS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 249,
     "status": "ok",
     "timestamp": 1669897108732,
     "user": {
      "displayName": "Mathis Randl",
      "userId": "00190129247534467029"
     },
     "user_tz": -60
    },
    "id": "v69t6G__jCUV"
   },
   "outputs": [],
   "source": [
    "def get_bert_embeddings(tokens_tensor, segments_tensors, model):\n",
    "    \"\"\"Get embeddings from an embedding model\n",
    "    \n",
    "    Args:\n",
    "        tokens_tensor (obj): Torch tensor size [n_tokens]\n",
    "            with token ids for each token in text\n",
    "        segments_tensors (obj): Torch tensor size [n_tokens]\n",
    "            with segment ids for each token in text\n",
    "        model (obj): Embedding model to generate embeddings\n",
    "            from token and segment ids\n",
    "    \n",
    "    Returns:\n",
    "        list: List of list of floats of size\n",
    "            [n_tokens, n_embedding_dimensions]\n",
    "            containing embeddings for each token\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(tokens_tensor, segments_tensors)\n",
    "        # Removing the first hidden state\n",
    "        # The first state is the input state\n",
    "        hidden_states = outputs[2][1:]\n",
    "\n",
    "    # Getting embeddings from the final BERT layer\n",
    "    token_embeddings = hidden_states[-1]\n",
    "    # Collapsing the tensor into 1-dimension\n",
    "    token_embeddings = torch.squeeze(token_embeddings, dim=0)\n",
    "    # Converting torchtensors to lists\n",
    "    list_token_embeddings = [token_embed.tolist() for token_embed in token_embeddings]\n",
    "\n",
    "    return list_token_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 525
    },
    "executionInfo": {
     "elapsed": 102102,
     "status": "error",
     "timestamp": 1669897757068,
     "user": {
      "displayName": "Mathis Randl",
      "userId": "00190129247534467029"
     },
     "user_tz": -60
    },
    "id": "gCNTxVJLjJvQ",
    "outputId": "4b41e5a6-b2e9-4f16-a5dc-6b7bca66ff09"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 10000/10000 [06:04<00:00, 27.42it/s]\n"
     ]
    }
   ],
   "source": [
    "# Getting embeddings for the target\n",
    "# word in all given contexts\n",
    "target_word_embeddings = []\n",
    "\n",
    "for text in tqdm.tqdm(test_data):\n",
    "    tokenized_text, tokens_tensor, segments_tensors = bert_text_preparation(text, tokenizer)\n",
    "    list_token_embeddings = get_bert_embeddings(tokens_tensor, segments_tensors, model)\n",
    "    sentence_embedding = list_token_embeddings[0]\n",
    "    target_word_embeddings.append(sentence_embedding)\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 236,
     "status": "ok",
     "timestamp": 1669897848472,
     "user": {
      "displayName": "Mathis Randl",
      "userId": "00190129247534467029"
     },
     "user_tz": -60
    },
    "id": "tT8s_yrsqBDx",
    "outputId": "e39a3959-c5c4-438b-c1c4-f701864c006c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_word_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "NXx3RJcpqfWc"
   },
   "outputs": [],
   "source": [
    "with open(\"data/pickle/test_data.pkl\", \"wb\") as f:\n",
    "    pickle.dump(target_word_embeddings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len("
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOqKaIOhqP6XVA/ZRIaCtBD",
   "mount_file_id": "1pb-gb9u6CGOjZdqj9jyTDQebKRa5Ae4k",
   "provenance": [
    {
     "file_id": "1pb-gb9u6CGOjZdqj9jyTDQebKRa5Ae4k",
     "timestamp": 1669897865713
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
